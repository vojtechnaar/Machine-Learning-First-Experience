#on basic data I want to see how does r2 change if I change tree depth, in other words what is the best depth after which there is overfit

import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error as mse
from sklearn.metrics import r2_score
from sklearn import tree

data = pd.read_csv("/Users/vojtechnaar/Desktop/Python/Test_data_csv/HPRICE1.csv")

print(data.head())

y = data["price"]
X = data[["assess", "bdrms", "lotsize", "sqrft", "colonial"]]

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)

r_squared_list = []
depth_list = []
for i in range(8):    
    i += 1
    model = DecisionTreeRegressor(max_depth = i)
    model.fit(x_train, y_train)

    y_predicted = model.predict(x_test)

    #print(y_predicted)
    #print(y_test)

    r2 = r2_score(y_test, y_predicted)
    r_squared_list.append(r2)
    depth_list.append(i)

#print(r2)

plt.plot(depth_list, r_squared_list)
plt.show()
plt.close()
#best max_depth = 4 at random_state = 1

#plt.plot(y_test, y_predicted, "o")
#plt.show()
#plt.close()

#tree.plot_tree(model, fontsize=6)
#plt.show()
#plt.close()
